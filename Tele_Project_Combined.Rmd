---
title: "Tele-Project-Combined"
author: "Fishbowlz"
date: "2023-10-25"
output: 
  html_document:
    code_folding: hide

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Calling Libraries 
## We are now calling in all the libraries that will be utilized in building all of our models. 
```{r}
library(dplyr)
library(caret)
library(neuralnet)
library(class)
```

# Download and examine data 
## We needed to read in our file and examine the structure of our variables and factorize them. 
```{r}
#Downloading and Prepping the Data
tele <- read.csv("tele.csv", stringsAsFactors = TRUE)
summary(tele)
str(tele)
```

# Clean Data
```{r}
#We are deleting the "duration" variable because it is an after the fact measurement. We only should be using variables that we know before the call
tele$duration <- NULL

# Deleting the column X
tele$X <- NULL

# Changing pdays to a dummy and deleting pdays
tele$pdaysdummy <- ifelse(tele$pdays == 999, 0, 1)
tele$pdays <- NULL

str(tele)
```

# Convert Factors to dummy variables 
## We are converting all of the factors into dummy variables as the input into knn has to be numeric
```{r}
# Using model.matrix to convert all the factors to dummy variables

telemm <- as.data.frame(model.matrix(~.-1,tele))
str(telemm)
```

# Normalize the data
## We needed to standardize the data so that when we run KNN and ANN models for the model to work best.
```{r}
#Normalize the data
normalize <- function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}

# we are going to normalize everything for KNN and ANN
tele_norm <- as.data.frame(lapply(telemm, normalize))
```


# Clusters
## We created 7 clusters to examine which groups are the most profitable  
```{r}

tele_norm_x <- tele_norm[,-53]
tele_clusters <- kmeans(tele_norm_x, 7)
tele_clusters$size

#tele_clusters$centers

tele_norm$cluster <- tele_clusters$cluster

tele_cluster_prob <- tapply(tele_norm$yyes, tele_norm$cluster, mean, na.rm = T)

```


## We now need to find the net profit using the most profitable cluster.
### Our process to do this was to use a dataframe that only includes clusters with higher than 20% accuracy. Then the number of true positives multiplied by the contribution margin of successful calls and the total average cost of 
```{r}
# This coding block will now be used to setup finding net profits of the most profitable clusters
# Makes a data frame of each cluster and the accuracy of each cluster
tele_cluster_prob_frame <- data.frame(unlist(names(tele_cluster_prob)), unlist(unname(tele_cluster_prob)))

# adds the size of each cluster to the newly made dataframe
tele_cluster_prob_frame$size <- tele_clusters$size

# renames the columns so that they are legible with their variables
names(tele_cluster_prob_frame) = c("cluster", "prob", "size")

# this makes a new dataframe that only includes clusters with a 20% accuracy or higher
tele_cluster_prob_greater <- dplyr::filter(tele_cluster_prob_frame, prob > 0.2)


# this just makes a list of all cluster numbers that are above 20%, shouldn't be necessary
#top_cluster <- tele_cluster_prob_greater$cluster

```

```{r}
#Finding profits for clusters
# The number of true positives times the contribution margin for successful calls, plus the number of false positives times the total average cost for each call ($1 variable cost + $1000 training cost/1000 calls per associate)
cluster_baseline_profits <- nrow(dplyr::filter(tele_norm, yyes == 1))*10 - nrow(dplyr::filter(tele_norm, yyes == 0))*2

# The baseline percentage of successful calls
cluster_percent_success_baseline <- nrow(tele_norm$yyes == "yes")/nrow(tele_norm)

# Creating a new column in the dataframe that shows probability of successful call from that cluster times the size of that cluster, thereby showing total number of successful calls from that cluster
tele_cluster_prob_greater$success_calls <- tele_cluster_prob_greater$prob * tele_cluster_prob_greater$size

tele_cluster_prob_greater$failed_calls <- tele_cluster_prob_greater$size - tele_cluster_prob_greater$success_calls

# Finding number of successful calls by adding up all rows from the new column in the data frame
cluster_numb_success_calls <- sum(tele_cluster_prob_greater$success_calls)
cluster_numb_failed_calls <- sum(tele_cluster_prob_greater$failed_calls)

# New percentage of successful calls
cluster_percent_success_new <- cluster_numb_success_calls / (cluster_numb_success_calls + cluster_numb_failed_calls)

cluster_new_avg_training_cost <- 1000/((cluster_percent_success_new - cluster_percent_success_baseline)*100*100 + 1000)

# Now I'm finding the new profits to account for the lower average training cost due to increased employee retention
cluster_net_profits <- cluster_numb_success_calls * 10 - cluster_numb_failed_calls*cluster_new_avg_training_cost


```
The Net Profits from the Clustering is `R cluster_net_profits`

# Building LM, ANN, KNN
## Split Data Into Test and Train
We are using a 70% proportion to build our model
```{r}
# 70 - 30 split
set.seed(12345)

tele_prop <- 0.7
train_tele <- sample(1:nrow(telemm),tele_prop*nrow(telemm))
tele_train <- telemm[train_tele, ]
tele_test <- telemm[-train_tele, ]

# normalized data is needed for ANN and KNN
train_tele_norm <- sample(1:nrow(tele_norm),tele_prop*nrow(tele_norm))
tele_norm_train <- tele_norm[train_tele_norm, ]
tele_norm_test <- tele_norm[-train_tele_norm, ]

# You need to separate the x and y from each other when using a KNN
tele_norm_train_x <- tele_norm_train[, -53]
tele_norm_test_x <- tele_norm_test[, -53]

tele_norm_train_y <- tele_norm_train[, 53]
tele_norm_test_y <- tele_norm_test[, 53]

```

## Logistic Model
### Build Logistic Model
## output was manually taken and and recorded below for computing efficiency 
```{r}
# the below line is commented because it is too taxing to run at the moment for testing, switch them out eventually
#tele_logistic <- glm(yyes ~. + .*., data = tele_train, family = "binomial")
tele_logistic <- glm(yyes ~., data = tele_train, family = "binomial")
tele_logistic_step <- step(tele_logistic, direction = "backward")

```

```{r}
summary(tele_logistic_step)
```

### Predict Logistic Model

```{r}
tele_logistic_pred <- predict(tele_logistic_step, tele_test, type = "response")
tele_logistic_pred_bin <- ifelse (tele_logistic_pred >= 0.5, 1, 0)
```

### Evaluate Logistic Model

```{r}
confusionMatrix(as.factor(tele_logistic_pred01), as.factor(tele_test$yyes), positive = "1")
```

## Articifial Neural Network
### Build Model
Due to constraints when building the model, we could not run in the Neural Network in this document. When we applied more layers an neurons we ended up with warnings like the following:
*Warning: Algorithm did not converge in 1 of 1 repetition(s) within the stepmax.*
While just a warning, this would result in the plotting failing. Because of this we are using a more limited ANN model which will be pulled in from a .cvs file at the end of this section.
```{r}

#tele_ann_model <- neuralnet(formula = `yyes` ~ .,
#                              data = tele_norm_train, hidden = 2)

# visualize the network topology
#plot(tele_ann_model)
```

### Predict and Evaluate ANN Model

```{r}
#tele_ann_pred <- predict(tele_ann_model, tele_norm_test)

#tele_ann_pred_bin <- ifelse(tele_ann_pred >= 0.5, 1, 0)

#confusionMatrix(as.factor(tele_ann_pred_bin), as.factor(tele_norm_test$yyes), positive = as.character(1))
```
### Read in ANN Predict
```{r}
import_ann <- read.csv("tele_ann_pred_output.csv")
str(import_ann)
tele_ann_pred_bin <- import_ann$V1
```


## KNN Model

### Build Model and Predict

```{r}
#its generally good to set K to the sqrt of the number of observations and then a bit smaller
tele_knn_pred_bin <- knn(tele_norm_train_x, tele_norm_test_x, tele_norm_train_y, k = round(sqrt(nrow(tele_norm_train))/5), )
```

### Evaluate
```{r}
confusionMatrix(as.factor(tele_knn_pred_bin), as.factor(tele_norm_test_y), positive = as.character(1))
```

## Voting!!!
```{r}
# makes a new data frame 
voting_data_frame <- data.frame(
  lm = as.numeric(tele_logistic_pred_bin),
  ann = as.numeric(tele_ann_pred_bin),
  knn = as.numeric(as.character(tele_knn_pred_bin))
)

# making a new column that sees if the average of the two predicitons and if above 0.5 then classifies as one
voting_data_frame$pred <- ifelse((voting_data_frame$lm + voting_data_frame$ann + voting_data_frame$knn) >= 2, 1, 0)

head(voting_data_frame, 20)
head(dplyr::filter(voting_data_frame, pred == 1), 20)
```
## Finding our Profitability! :)
```{r}
confusion_matrix <- confusionMatrix(as.factor(voting_data_frame$pred), as.factor(tele_norm_test$yyes), positive = as.character(1))

# The number of true positives times the contribution margin for successful calls, plus the number of false positives times the total average cost for each call ($1 variable cost + $1000 training cost/1000 calls per associate)
baseline_profits <- nrow(dplyr::filter(tele_norm, yyes == 1))*10 - nrow(dplyr::filter(tele_norm, yyes == 0))*2

# The baseline percentage of successful calls
percent_success_baseline <- nrow(tele_norm$yyes == "yes")/nrow(tele_norm)

# New percentage of successful calls
percent_success_new <- confusion_matrix$table[2, 2] / (confusion_matrix$table[2, 2] + confusion_matrix$table[2, 1])

new_avg_training_cost <- 1000/((percent_success_new - percent_success_baseline)*100*100 + 1000)

# Now I'm finding the new profits to account for the lower average training cost due to increased employee retention
new_profits <- confusion_matrix$table[2, 2]*10 - confusion_matrix$table[2, 1]*new_avg_training_cost

print(baseline_profits)
print(new_profits)
```
